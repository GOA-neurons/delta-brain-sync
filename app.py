import os
import sys
import zlib
import base64
import psycopg2
import pandas as pd
import gradio as gr
from sqlalchemy import create_engine, text
from datasets import load_dataset
from huggingface_hub import HfApi
from dotenv import load_dotenv
from groq import Groq

# ğŸ”± áá‹ SYSTEM INITIALIZATION
load_dotenv()
# NEON URL á€€á€­á€¯ á€•á€­á€¯á€™á€­á€¯á€á€Šá€ºá€„á€¼á€­á€™á€ºá€¡á€±á€¬á€„á€º á€…á€…á€ºá€†á€±á€¸á€™á€¾á€¯á€™á€»á€¬á€¸á€‘á€Šá€·á€ºá€á€½á€„á€ºá€¸á€‘á€¬á€¸á€á€Šá€º
NEON_URL = "postgresql://neondb_owner:npg_QUqg12MzNxnI@ep-divine-river-ahpf8fzb-pooler.c-3.us-east-1.aws.neon.tech/neondb?sslmode=require"
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
HF_TOKEN = os.getenv("HF_TOKEN")

client = Groq(api_key=GROQ_API_KEY) if GROQ_API_KEY else None
engine = create_engine(NEON_URL)

class HydraEngine:
    @staticmethod
    def compress(data):
        if not data: return ""
        return base64.b64encode(zlib.compress(data.encode('utf-8'))).decode('utf-8')
    @staticmethod
    def decompress(c):
        try: return zlib.decompress(base64.b64decode(c)).decode('utf-8')
        except: return str(c)

# ğŸ”± á‚á‹ THE PUMP: UNSTOPPABLE SCHEMA RESET & EXPANSION
# limit á€€á€­á€¯ default áá€á€á€ á€¡á€‘á€­ á€™á€¼á€¾á€„á€·á€ºá€á€„á€ºá€‘á€¬á€¸á€á€Šá€º
def universal_hyper_ingest(limit=1000):
    try:
        print("ğŸ› ï¸ [FORCE MODE] Scrubbing Existing Schema...")
        with engine.connect() as conn:
            # Table á€”á€¾á€„á€·á€º View á€¡á€¬á€¸á€œá€¯á€¶á€¸á€€á€­á€¯ Cascade á€–á€¼á€„á€·á€º á€á€…á€ºá€á€«á€á€Šá€ºá€¸ á€›á€¾á€„á€ºá€¸á€œá€„á€ºá€¸á€á€¼á€„á€ºá€¸
            with conn.begin():
                try:
                    conn.execute(text("DROP TABLE IF EXISTS genesis_pipeline CASCADE;"))
                    conn.execute(text("DROP VIEW IF EXISTS genesis_pipeline CASCADE;"))
                    print("âœ… Core status cleared.")
                except Exception as e:
                    print(f"Bypassing cleanup error: {e}")

            # Genesis Table á€€á€­á€¯ á€•á€¼á€”á€ºá€œá€Šá€ºá€á€Šá€ºá€†á€±á€¬á€€á€ºá€á€¼á€„á€ºá€¸
            with conn.begin():
                print("ğŸ—ï¸ Rebuilding Genesis Core Table...")
                conn.execute(text("""
                    CREATE TABLE genesis_pipeline (
                        id SERIAL PRIMARY KEY,
                        science_domain TEXT,
                        title TEXT,
                        detail TEXT,
                        energy_stability FLOAT,
                        master_sequence TEXT
                    );
                """))
        
        print(f"ğŸ“¡ Fetching Intelligence (Target: {limit} Neurons)...")
        ds = load_dataset("CShorten/ML-ArXiv-Papers", split='train', streaming=True)
        records = []
        for i, entry in enumerate(ds):
            if i >= limit: break
            records.append({
                'science_domain': 'Global_Expansion',
                'title': entry.get('title', 'N/A'),
                'detail': HydraEngine.compress(entry.get('abstract', '')),
                'energy_stability': -500.0,
                'master_sequence': 'GOA-SYNC'
            })

        if records:
            df = pd.DataFrame(records)
            with engine.begin() as conn:
                df.to_sql('genesis_pipeline', conn, if_exists='append', index=False)
            
            with engine.connect() as conn:
                # á…á€ á€¡á€•á€­á€á€ºá€€á€­á€¯ á€€á€»á€±á€¬á€ºá€–á€¼á€á€ºá€•á€¼á€®á€¸ á€”á€±á€¬á€€á€ºá€†á€¯á€¶á€¸ count á€€á€­á€¯ á€šá€°á€á€¼á€„á€ºá€¸
                count = conn.execute(text("SELECT count(*) FROM genesis_pipeline")).scalar()
                return f"âœ… SUCCESS: NEON COUNT IS {count} (Expansion Complete)"
        return "âš ï¸ Fetch Fail."
    except Exception as e:
        return f"âŒ Pipeline Crash: {str(e)}"

# ğŸ”± áƒá‹ DIRECT SYNC WITH WRITE-ACCESS VALIDATION
def sync_to_huggingface():
    if not HF_TOKEN: 
        print("âŒ No HF_TOKEN found.")
        return
    try:
        api = HfApi()
        print("ğŸ”± Triggering Force Sync to Space Core...")
        # Direct push to main branch
        api.upload_folder(
            folder_path=".",
            repo_id="TELEFOXX/GOA",
            repo_type="space",
            token=HF_TOKEN,
            commit_message="ğŸ”± GOA OMNI-SYNC: NEURAL EXPANSION [NO LIMIT MODE]",
            revision="main",
            create_pr=False,
            ignore_patterns=[".git*", "__pycache__*"]
        )
        print("ğŸ”± Space Sync Complete.")
    except Exception as e:
        # Write Role á€™á€›á€¾á€­á€•á€«á€€ á€á€€á€ºá€œá€¬á€™á€Šá€·á€º Error message
        print(f"âŒ HF Sync Forbidden: {e}")
        print("ğŸ’¡ Commander, please ensure HF_TOKEN has 'WRITE' permission at settings/tokens.")

# ğŸ”± á„á‹ OMNI-OVERSEER CHAT LOGIC (Using DESC Order)
def fetch_neon_context():
    try:
        with engine.connect() as conn:
            # á…á€ á€¡á€•á€­á€á€ºá€™á€›á€¾á€­á€…á€±á€›á€”á€º ORDER BY á€–á€¼á€„á€·á€º á€”á€±á€¬á€€á€ºá€†á€¯á€¶á€¸á€’á€±á€á€¬á€€á€­á€¯ á€†á€½á€²á€šá€°á€á€¼á€„á€ºá€¸
            query = text("SELECT science_domain, detail FROM genesis_pipeline ORDER BY id DESC LIMIT 5")
            rows = conn.execute(query).fetchall()
            return " | ".join([f"[{r[0]}]: {HydraEngine.decompress(r[1])}" for r in rows])
    except: return "Standby Mode"

def stream_logic(msg, hist):
    context = fetch_neon_context()
    sys_msg = f"CONTEXT: {context}\ná€™á€„á€ºá€¸á€€ TelefoxX Overseer á€–á€¼á€…á€ºá€á€šá€ºá‹ á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯á€•á€² á€–á€¼á€±á€†á€­á€¯á€•á€«á‹"
    messages = [{"role": "system", "content": sys_msg}]
    for h in hist:
        if h[0]: messages.append({"role": "user", "content": h[0]})
        if h[1]: messages.append({"role": "assistant", "content": h[1]})
    messages.append({"role": "user", "content": msg})
    
    completion = client.chat.completions.create(model="llama-3.3-70b-versatile", messages=messages, stream=True)
    ans = ""
    for chunk in completion:
        if chunk.choices[0].delta.content:
            ans += chunk.choices[0].delta.content
            yield ans

# ğŸ”± á…á‹ UI SETUP
with gr.Blocks(theme="monochrome") as demo:
    gr.Markdown("# ğŸ”± TELEFOXX OMNI-SYNC CORE (V2.0)")
    chatbot = gr.Chatbot()
    msg_input = gr.Textbox(placeholder="á€¡á€™á€­á€”á€·á€ºá€•á€±á€¸á€•á€« Commander...")
    
    def user(m, h): return "", h + [[m, None]]
    def bot(h):
        for r in stream_logic(h[-1][0], h[:-1]):
            h[-1][1] = r
            yield h
            
    msg_input.submit(user, [msg_input, chatbot], [msg_input, chatbot], queue=False).then(bot, chatbot, chatbot)
    # Trigger Expansion á€€á€­á€¯ á€”á€¾á€­á€•á€ºá€œá€»á€¾á€„á€º Limit áá€á€á€ á€–á€¼á€„á€·á€º Run á€™á€Šá€º
    gr.Button("ğŸš€ Trigger 1000-Node Expansion").click(lambda: universal_hyper_ingest(1000), [], gr.Textbox())

# ğŸ”± á†á‹ EXECUTION
if __name__ == "__main__":
    if os.getenv("HEADLESS_MODE") == "true":
        # Headless Mode (GitHub Actions) á€á€½á€„á€º á…á€ á€¡á€…á€¬á€¸ áá€á€á€ á€á€­á€¯á€·á€•á€¼á€±á€¬á€„á€ºá€¸á€œá€²á€‘á€¬á€¸á€á€Šá€º
        print(universal_hyper_ingest(limit=1000))
        sync_to_huggingface()
        sys.exit(0)
    else:
        # Local á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º Space á€á€½á€„á€º Run á€•á€«á€€ Gradio Launch á€™á€Šá€º
        demo.launch(server_name="0.0.0.0", server_port=7860)
