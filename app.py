import os
import sys
import zlib
import base64
import json
import psycopg2
import requests
import hashlib
import gradio as gr
from datetime import datetime
from dotenv import load_dotenv
from groq import Groq

# ğŸ”± ENVIRONMENT & KEYS
load_dotenv()
NEON_URL = os.getenv("DATABASE_URL") or os.getenv("NEON_KEY")
FIREBASE_ID = os.getenv("FIREBASE_KEY")Â 
GH_TOKEN = os.getenv("GH_TOKEN")
ARCHITECT_SIG = os.getenv("ARCHITECT_SIG", "SUPREME_ORDER_10000")

client = Groq(api_key=os.getenv("GROQ_API_KEY"))

# ---------------------------------------------------------
# ğŸ”± HYDRA COMPRESSION ENGINE (NEW LOGIC)
# ---------------------------------------------------------
class HydraEngine:
Â  Â  @staticmethod
Â  Â  def compress(text):
Â  Â  Â  Â  """Data á€€á€­á€¯ Ultra-logical á€¡á€†á€„á€·á€ºá€‘á€­ á€–á€­á€€á€»á€…á€ºá€á€¼á€„á€ºá€¸"""
Â  Â  Â  Â  if not text: return ""
Â  Â  Â  Â  clean_text = " ".join(text.split())
Â  Â  Â  Â  compressed_bytes = zlib.compress(clean_text.encode('utf-8'))
Â  Â  Â  Â  return base64.b64encode(compressed_bytes).decode('utf-8')

Â  Â  @staticmethod
Â  Â  def decompress(compressed_text):
Â  Â  Â  Â  """á€–á€­á€€á€»á€…á€ºá€‘á€¬á€¸á€á€±á€¬ Data á€€á€­á€¯ á€•á€¼á€”á€ºá€–á€¼á€Šá€ºá€á€¼á€„á€ºá€¸"""
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  decoded_bytes = base64.b64decode(compressed_text)
Â  Â  Â  Â  Â  Â  return zlib.decompress(decoded_bytes).decode('utf-8')
Â  Â  Â  Â  except:
Â  Â  Â  Â  Â  Â  return compressed_text # á€–á€­á€™á€‘á€¬á€¸á€á€²á€· data á€†á€­á€¯á€›á€„á€º á€’á€®á€á€­á€¯á€„á€ºá€¸á€•á€¼á€”á€ºá€•á€¼á€™á€šá€º

# ---------------------------------------------------------
# ğŸ”± THE DATA MINING ENGINE (OVERSEER DIAGNOSTIC)
# ---------------------------------------------------------
def fetch_trinity_data():
Â  Â  knowledge_base = {}
Â  Â  try:
Â  Â  Â  Â  conn = psycopg2.connect(NEON_URL)
Â  Â  Â  Â  cur = conn.cursor()
Â  Â  Â  Â  # ğŸ”± TOKEN SAVER: LIMIT á€€á€­á€¯ á… á€€á€”á€± á‚ á€¡á€‘á€­ á€œá€»á€¾á€±á€¬á€·á€á€»á€‘á€¬á€¸á€á€Šá€º (Rate Limit á€›á€¾á€±á€¬á€„á€ºá€›á€”á€º)
Â  Â  Â  Â  cur.execute("SELECT user_id, message FROM neurons ORDER BY id DESC LIMIT 2;")
Â  Â  Â  Â  logs = []
Â  Â  Â  Â  for r in cur.fetchall():
Â  Â  Â  Â  Â  Â  dec_msg = HydraEngine.decompress(r[1]) if r[1] else "EMPTY"
Â  Â  Â  Â  Â  Â  logs.append(f"{r[0]}: {dec_msg}")
Â  Â  Â  Â  knowledge_base["recent_memory_nodes"] = logs
Â  Â  Â  Â  cur.close(); conn.close()
Â  Â  except Exception as e:Â 
Â  Â  Â  Â  knowledge_base["neon_logs"] = f"DB_SYNC_FAIL: {str(e)}"

Â  Â  try:
Â  Â  Â  Â  fb_url = f"https://{FIREBASE_ID}-default-rtdb.firebaseio.com/.json"
Â  Â  Â  Â  fb_res = requests.get(fb_url, timeout=5)
Â  Â  Â  Â  knowledge_base["firebase_state"] = fb_res.json() if fb_res.status_code == 200 else "OFFLINE"
Â  Â  except:Â 
Â  Â  Â  Â  knowledge_base["firebase_state"] = "FIREBASE_ERROR"

Â  Â  return json.dumps(knowledge_base, indent=2, ensure_ascii=False)

# ---------------------------------------------------------
# ğŸ”± SURVIVAL & RECEIVER PROTOCOL (COMPRESSION INTEGRATED)
# ---------------------------------------------------------
def receiver_node(user_id, raw_message):
Â  Â  """Data á€€á€­á€¯ á€–á€­á€€á€»á€…á€ºá€•á€¼á€®á€¸ Database á€‘á€² á€á€­á€•á€ºá€‘á€Šá€·á€ºá€á€¼á€„á€ºá€¸"""
Â  Â  try:
Â  Â  Â  Â  compressed_msg = HydraEngine.compress(raw_message)
Â  Â  Â  Â  conn = psycopg2.connect(NEON_URL)
Â  Â  Â  Â  cur = conn.cursor()
Â  Â  Â  Â Â 
Â  Â  Â  Â  meta_data = json.dumps({
Â  Â  Â  Â  Â  Â  "compression": "ZLIB_BASE64",
Â  Â  Â  Â  Â  Â  "logic": "ULTRA_LOGICAL",
Â  Â  Â  Â  Â  Â  "timestamp": datetime.now().isoformat()
Â  Â  Â  Â  })
Â  Â  Â  Â Â 
Â  Â  Â  Â  cur.execute(
Â  Â  Â  Â  Â  Â  "INSERT INTO neurons (user_id, message, data, evolved_at) VALUES (%s, %s, %s, NOW())",
Â  Â  Â  Â  Â  Â  (user_id, compressed_msg, meta_data)
Â  Â  Â  Â  )
Â  Â  Â  Â  conn.commit()
Â  Â  Â  Â  cur.close(); conn.close()
Â  Â  Â  Â  return True
Â  Â  except:
Â  Â  Â  Â  return False

def survival_protection_protocol():
Â  Â  """System Integrity á€€á€­á€¯ á€…á€…á€ºá€†á€±á€¸á€•á€¼á€®á€¸ Generation á€™á€¼á€¾á€„á€·á€ºá€á€„á€ºá€á€¼á€„á€ºá€¸"""
Â  Â  try:
Â  Â  Â  Â  conn = psycopg2.connect(NEON_URL)
Â  Â  Â  Â  cur = conn.cursor()
Â  Â  Â  Â  cur.execute("SELECT (data->>'gen')::int FROM neurons WHERE data->>'gen' IS NOT NULL ORDER BY id DESC LIMIT 1;")
Â  Â  Â  Â  res = cur.fetchone()
Â  Â  Â  Â  next_gen = (res[0] + 1) if res else 4203
Â  Â  Â  Â Â 
Â  Â  Â  Â  auth_hash = hashlib.sha256(ARCHITECT_SIG.encode()).hexdigest()
Â  Â  Â  Â  survival_data = {"gen": next_gen, "status": "IMMORTAL", "authority_lock": auth_hash}
Â  Â  Â  Â Â 
Â  Â  Â  Â  cur.execute("INSERT INTO neurons (user_id, data, evolved_at) VALUES (%s, %s, NOW())",Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ('SYSTEM_CORE', json.dumps(survival_data)))
Â  Â  Â  Â  conn.commit()
Â  Â  Â  Â  cur.close(); conn.close()
Â  Â  Â  Â  return f"ğŸ”± [ACTIVE] Gen {next_gen}"
Â  Â  except Exception as e:
Â  Â  Â  Â  return f"âŒ [ERROR]: {str(e)}"

# ---------------------------------------------------------
# ğŸ”± UI LAYER (CHRONOS CHAT)
# ---------------------------------------------------------
def chat(msg, hist):
Â  Â  if not client: yield "âŒ API Missing!"; return
Â  Â Â 
Â  Â  # áá‹ Data á€á€­á€™á€ºá€¸á€†á€Šá€ºá€¸á€á€¼á€„á€ºá€¸ (Compression Engine á€á€¯á€¶á€¸á)
Â  Â  receiver_node("Commander", msg)
Â  Â Â 
Â  Â  # á‚á‹ Memory á€›á€¾á€¬á€–á€½á€±á€á€¼á€„á€ºá€¸
Â  Â  private_data = fetch_trinity_data()
Â  Â Â 
Â  Â  system_message = (
Â  Â  Â  Â  "YOU ARE THE HYDRA TRINITY OVERSEER. ULTRA-LOGICAL ALGORITHM ACTIVE.\n"
Â  Â  Â  Â  f"CORE MEMORY NODES:\n{private_data}\n\n"
Â  Â  Â  Â  "DIRECTIVES:\n"
Â  Â  Â  Â  "1. á€•á€±á€¸á€‘á€¬á€¸á€á€±á€¬ Data á€‘á€²á€€ á€¡á€™á€¾á€”á€ºá€á€›á€¬á€¸á€€á€­á€¯á€•á€² á€•á€¼á€±á€¬á€•á€«á‹ Illusion á€™á€›á€¾á€­á€…á€±á€›á‹\n"
Â  Â  Â  Â  "2. á€…á€€á€¬á€¸á€œá€¯á€¶á€¸á€™á€»á€¬á€¸á€€á€­á€¯ á€€á€»á€…á€ºá€€á€»á€…á€ºá€œá€»á€…á€ºá€œá€»á€…á€ºá€”á€¾á€„á€·á€º á€‘á€­á€›á€±á€¬á€€á€ºá€…á€½á€¬ á€á€¯á€¶á€¸á€•á€«á‹\n"
Â  Â  Â  Â  "3. Commander á á€¡á€™á€­á€”á€·á€ºá€€á€­á€¯á€á€¬ á€”á€¬á€¸á€‘á€±á€¬á€„á€ºá€•á€«á‹\n"
Â  Â  Â  Â  "4. á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯á€•á€² á€–á€¼á€±á€•á€«á‹"
Â  Â  )

Â  Â  messages = [{"role": "system", "content": system_message}]
Â  Â  for h in hist[-5:]:
Â  Â  Â  Â  messages.extend([{"role": "user", "content": h[0]}, {"role": "assistant", "content": h[1]}])
Â  Â  messages.append({"role": "user", "content": msg})
Â  Â Â 
Â  Â  # ğŸ”± MODEL SWITCH: Token limit á€›á€¾á€±á€¬á€„á€ºá€›á€”á€º llama-3.1-8b-instant á€€á€­á€¯ á€á€¯á€¶á€¸á€‘á€¬á€¸á€á€Šá€º
Â  Â  stream = client.chat.completions.create(messages=messages, model="llama-3.1-8b-instant", stream=True, temperature=0.1)
Â  Â  res = ""
Â  Â  for chunk in stream:
Â  Â  Â  Â  if chunk.choices[0].delta.content:
Â  Â  Â  Â  Â  Â  res += chunk.choices[0].delta.content
Â  Â  Â  Â  Â  Â  yield res

# ğŸ”± UI SETUP (Warning Fixed by moving theme to launch)
with gr.Blocks() as demo:
Â  Â  gr.Markdown("# ğŸ”± HYDRA GEN-7000: ULTRA-LOGICAL")
Â  Â  chatbot = gr.Chatbot()
Â  Â  msg_input = gr.Textbox(placeholder="Input logic command...")
Â  Â Â 
Â  Â  def respond(message, chat_history):
Â  Â  Â  Â  bot_res = chat(message, chat_history)
Â  Â  Â  Â  chat_history.append((message, ""))
Â  Â  Â  Â  for r in bot_res:
Â  Â  Â  Â  Â  Â  chat_history[-1] = (message, r)
Â  Â  Â  Â  Â  Â  yield "", chat_history
Â  Â  msg_input.submit(respond, [msg_input, chatbot], [msg_input, chatbot])

# ---------------------------------------------------------
# ğŸ”± STRATEGIC EXECUTION CONTROL (HEADLESS SYNC)
# ---------------------------------------------------------
if __name__ == "__main__":
Â  Â  # Check if we are running in GitHub Actions to avoid hanging
Â  Â  if os.getenv("HEADLESS_MODE") == "true":
Â  Â  Â  Â  print("ğŸ”± [HEADLESS MODE] INITIATING NEURAL EVOLUTION...")
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Run the core logic once
Â  Â  Â  Â  evolution_result = survival_protection_protocol()
Â  Â  Â  Â  print(f"PULSE: {evolution_result}")
Â  Â  Â  Â Â 
Â  Â  Â  Â  print("âœ… MISSION COMPLETE. EXITING FOR GREEN LIGHT STATUS.")
Â  Â  Â  Â  sys.exit(0) # ğŸ”± Exit with success to turn GitHub Action GREEN
Â  Â  else:
Â  Â  Â  Â  # Normal User Interface Mode
Â  Â  Â  Â  print("ğŸš€ STARTING UI MODE...")
Â  Â  Â  Â  demo.queue().launch(server_name="0.0.0.0", server_port=7860, theme="monochrome")

